


### Loading Dependancy 
- Import initial set up
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

#Configuration for Cleaner Visuals
sns.set(style='whitegrid')
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
# Load datasets 
df_airports = pd.read_csv('/Users/sampadachavan/Downloads/data/Airport_Codes.csv')
df_flights = pd.read_csv('/Users/sampadachavan/Downloads/data/Flights.csv')
df_tickets = pd.read_csv('/Users/sampadachavan/Downloads/data/Tickets.csv')
## Airport_Codes Data set
print(f"Airport Data Shape: {df_airports.shape}")
df_airports.head()
### Data cleaning, Filtering and Handling NA values

- Selecting large and medium airport from US.

- Eliminating invalid IATA codes.

- Spliting Coordinates columns for geospatial Visualization.

# Filtering only US-based medium & large airports with valid IATA codes
df_airports_filtered = df_airports.copy()
df_airports_filtered = df_airports_filtered[
    (df_airports_filtered['TYPE'].isin(['medium_airport', 'large_airport'])) &
    (df_airports_filtered['ISO_COUNTRY'] == 'US') &
    (df_airports_filtered['IATA_CODE'].notna())]


# Spliting COORDINATES into longitude and latitude
df_airports_filtered[['longitude', 'latitude']] = df_airports_filtered['COORDINATES'].str.split(',', expand=True)
df_airports_filtered['longitude'] = df_airports_filtered['longitude'].astype(float)
df_airports_filtered['latitude'] = df_airports_filtered['latitude'].astype(float)
df_airports_filtered.head()
#Dropping Unwanted columns
df_airports_filtered.drop(columns=['CONTINENT','ISO_COUNTRY','COORDINATES'],inplace=True)
df_airports_filtered.head()
- Calculating Total no. of Airport for each type
df_airports_filtered.TYPE.value_counts()
# Checking Null values in filtered data
df_airports_filtered.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

# Seting style
sns.set_style("whitegrid", {'grid.linestyle': ':'})
plt.figure(figsize=(8, 4))

# Geting counts and percentages
type_counts = df_airports_filtered['TYPE'].value_counts()
percentages = type_counts / type_counts.sum() * 100

# Creating gradient bars
ax = sns.barplot(x=type_counts.index, 
                 y=type_counts.values,
                 palette=["#1f77b4", "#ff7f0e"],  
                 saturation=0.8,
                 edgecolor="black",
                 linewidth=1.5)

# Adding value labels
for i, (count, pct) in enumerate(zip(type_counts.values, percentages)):
    ax.text(i, count + max(type_counts)*0.05, 
            f"{count}\n({pct:.1f}%)", 
            ha='center', 
            va='bottom',
            fontsize=11,
            bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=2))

# Styling Axis for better visuals
plt.title("Distribution of Airport Types", pad=20, fontsize=14, fontweight='bold')
plt.xlabel("")
plt.ylabel("Count", labelpad=10)
plt.ylim(0, max(type_counts)*1.2)
sns.despine(top=True, right=True)
plt.tight_layout()
plt.show()
# Tickets Data set
- Ticket dataset is given for Quarter 1 of 2019 Checked and confirmed that there is only one value in the array  ----  Year- ie 2019 and  Quarter -'1' 

- Consider only Round trips as per instruction 

- Therefore ITIN_FARE is Round trip fare as given in metadata
df_tickets_filtered= df_tickets.copy()
print(f"Ticket Data Shape: {df_tickets_filtered.shape}")
df_tickets_filtered.head()
df_tickets_filtered['TRIP_NAME'] = df_tickets_filtered.apply(lambda row: '_'.join(sorted([row['ORIGIN'], row['DESTINATION']])),axis=1)
# Printing Rows where ITIN_ID appears more than once
dupes = df_tickets_filtered[df_tickets_filtered['ITIN_ID'].duplicated(keep=False)]
print(dupes)
# Checked whether ITIN_ID's data is exactly same accross all the columns
df_one = df_tickets_filtered.loc[df_tickets_filtered['ITIN_ID'] == 201912723755]
df_one.head()
# Droping duplicate ITIN_ID for geting Unique Itinery id's 
df_tickets_filtered.drop_duplicates(subset='ITIN_ID', keep='first', inplace=True)

#Filtering only round trip
df_tickets_filtered=df_tickets_filtered[(df_tickets_filtered['ROUNDTRIP'].isin([1]))]
print(f"Ticket Data Shape: {df_tickets_filtered.shape}")
df_tickets_filtered.head()
#checking null values in the dataframe
print(df_tickets_filtered.isnull().sum())


# Droping this column as its mention we have to consider Occupancy rate from flights data to calculate Total no of Passenger from the respective flights
df_tickets_filtered = df_tickets_filtered.drop(columns=['PASSENGERS'])
# Converting data type of ITIN_FARE for calculation
df_tickets_filtered['ITIN_FARE'] = pd.to_numeric(df_tickets_filtered['ITIN_FARE'], errors='coerce')
print(df_tickets_filtered.isnull().sum())
### Handling NA values and Invalid  values of ITIN_Fare 

- Checked the distribution, maximum and minimum value  of the Round trip fare 

- After research I found  Values below $39 or above $10000 are unlikely for a one-way airline fare and often indicate typos, misplaced decimals, or currency‐conversion mistakes.

-    Extreme fares can skew summary statistics (mean, variance) and distort visualizations or models, leading to misleading insights.

-    Based on historical pricing data for (Economy class to First class ), valid domestic fares typically fall within this range hence removed values outside to keep dataset aligned with real-world expectations.

upper = df_tickets_filtered['ITIN_FARE'].quantile(0.99)
print("upper",upper)
fares = df_tickets_filtered['ITIN_FARE'].dropna()
min_fare = fares.min()
print("Minimum ITIN_FARE:", min_fare)
highest_fare = df_tickets_filtered['ITIN_FARE'].dropna().max()
print("Highest fare:", highest_fare)

dq_graph=df_tickets_filtered.copy()
# filtering ticket price less than $39 and more than $ 100000
df_tickets_filtered = df_tickets_filtered[
    (df_tickets_filtered['ITIN_FARE'] >= 39) &
    (df_tickets_filtered['ITIN_FARE'] <= 10000)
].copy()
# Null values were treated automatically after droping invalid ticket prices
print(df_tickets_filtered.isnull().sum())
# Calculating average ticket price with respect to each trip
df_tickets_filtered['avg_roundtrip_fare'] = (df_tickets_filtered.groupby('TRIP_NAME')['ITIN_FARE'].transform('mean'))

# Divide by 2 to get an approximate one-way fare
df_tickets_filtered['Ticket_price'] = (df_tickets_filtered['avg_roundtrip_fare'] / 2).round(2)
df_ticket_prices = df_tickets_filtered.groupby('TRIP_NAME', as_index=False)['Ticket_price'].mean()
display(df_ticket_prices.head())
#checked whether we have any null values as will use this table to map in our Enriched data
df_ticket_prices.isnull().sum()

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import gaussian_kde

data = df_ticket_prices['Ticket_price']
kde = gaussian_kde(data)

# histogram
plt.figure()
counts, bins, _ = plt.hist(data, bins=30, density=True)
# density line
xx = np.linspace(0, 15000, 200)
plt.plot(xx, kde(xx))
plt.xlim(0, 15000)
plt.title('Histogram with Density of Mean Ticket Prices')
plt.xlabel('Mean Ticket Price ($)')
plt.ylabel('Density')
plt.tight_layout()
plt.show()



import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import gaussian_kde
from matplotlib.ticker import FuncFormatter

# Use your actual DataFrame column here
data = df_ticket_prices['Ticket_price']

# Compute kernel density estimate
kde = gaussian_kde(data)

# Create figure
plt.figure(figsize=(10, 6))

# Histogram
counts, bins, patches = plt.hist(
    data, bins=30, density=True, alpha=0.6, color='skyblue',
    edgecolor='black', label='Histogram (Normalized)'
)

# KDE line
xx = np.linspace(min(data), max(data), 500)
plt.plot(xx, kde(xx), color='darkblue', linewidth=2, label='Density Estimate (KDE)')

# Add mean and median lines
mean_val = np.mean(data)
median_val = np.median(data)
plt.axvline(mean_val, color='red', linestyle='--', linewidth=1.5, label=f'Mean = ${mean_val:,.0f}')
plt.axvline(median_val, color='green', linestyle='--', linewidth=1.5, label=f'Median = ${median_val:,.0f}')

# Custom X-axis limits and ticks
plt.xlim(0, 1000)
plt.xticks(np.arange(0, 1001, 100))

# Format x-tick labels as currency
formatter = FuncFormatter(lambda x, _: f'${int(x):,}')
plt.gca().xaxis.set_major_formatter(formatter)

# Labels and title
plt.title('Distribution of Ticket Prices', fontsize=14, weight='bold')
plt.xlabel('Ticket Price ($)', fontsize=12)
plt.ylabel('Density', fontsize=12)

# Grid and legend
plt.grid(True, linestyle='--', alpha=0.5)
plt.legend()
plt.tight_layout()
plt.show()

## picking the 10 highest‐fare routes
df_top10 = (df_ticket_prices.drop_duplicates('TRIP_NAME', keep='first').nlargest(10, 'Ticket_price'))
df_top10.head(10)
import numpy as np
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(10, 6))

# picking colors palete
cmap   = plt.get_cmap('viridis')
colors = cmap(np.linspace(0.2, 0.8, len(df_top10)))

# drawing bars with a narrower width
bars = ax.bar(
    df_top10['TRIP_NAME'],
    df_top10['Ticket_price'],
    width=0.5,          
    color=colors
)

# grid and margins
ax.grid(axis='y', linestyle='--', alpha=0.4)
ax.margins(x=0.02)      

# bold labels on each bar
ax.bar_label(
    bars,
    labels=[f"{h:.2f}" for h in df_top10['Ticket_price']],
    padding=4,
    fontsize=12,
    fontweight='bold'    
)

# titles & axes
ax.set_title('Top 10 Trip Routes by Average One-way Fare', 
             fontsize=14, fontweight='bold')
ax.set_xlabel('Trip Name')
ax.set_ylabel('Average One-way Fare ($)')

plt.xticks(rotation=0)  
plt.tight_layout()
plt.show()


# Flights Dataset

# Basic exploration
print("Flights Data:")
print(f"Data Shape: {df_flights.shape}")
df_flights.head()

df_flights_filtered= df_flights.copy()
# Joining all three data set

- Clean & uppercase ORIGIN/DESTINATION codes.

- Annotate each flight with origin & destination airport TYPE.

- Build a canonical (sorted) TRIP_NAME on both flights & ticket_prices.

- Join in the ticket_price by that canonical TRIP_NAME.

import pandas as pd
def enrich_and_join_flights(
    df_flights_filtered: pd.DataFrame,
    df_airports_filtered: pd.DataFrame,
    df_ticket_prices: pd.DataFrame
) -> pd.DataFrame:

    # Work on copies to avoid side effects
    flights = df_flights_filtered.copy()
    airports = df_airports_filtered.copy()
    prices  = df_ticket_prices.copy()

    #Cleaning up codes for ensuring proper mapping
    for col in ['ORIGIN', 'DESTINATION']:
        flights[col] = flights[col].str.strip().str.upper()

    #Canonicalize the ticket_prices table's TRIP_NAME
    def _canon(name: str) -> str:
        parts = name.strip().upper().split('_')
        return '_'.join(sorted(parts))

    prices['TRIP_NAME'] = prices['TRIP_NAME'].apply(_canon)

    # Building airport‐type lookup
    airport_types = (
        airports[['IATA_CODE','TYPE']]
        .rename(columns={'IATA_CODE':'CODE','TYPE':'AIRPORT_TYPE'})
    )
    airport_types['CODE'] = airport_types['CODE'].str.strip().str.upper()

    # Merging origin & destination types
    flights = (
        flights
        .merge(airport_types.rename(columns={'AIRPORT_TYPE':'ORIGIN_AIRPORT_TYPE'}),
               left_on='ORIGIN', right_on='CODE', how='left')
        .drop(columns=['CODE'])
        .merge(airport_types.rename(columns={'AIRPORT_TYPE':'DESTINATION_AIRPORT_TYPE'}),
               left_on='DESTINATION', right_on='CODE', how='left')
        .drop(columns=['CODE'])
    )

    #Computing canonical TRIP_NAME on the flights side
    flights['TRIP_NAME'] = flights.apply(
        lambda r: '_'.join(sorted([r['ORIGIN'], r['DESTINATION']])),
        axis=1
    )
    #merging flights with tickets data
    enriched = flights.merge(prices, on='TRIP_NAME', how='left')

    return enriched

df_enriched = enrich_and_join_flights(
    df_flights_filtered,
    df_airports_filtered,
    df_ticket_prices
)
print(df_enriched[['ORIGIN','DESTINATION','TRIP_NAME','Ticket_price']].head())
print(df_enriched.shape)
print(df_enriched.columns.tolist())
df_enriched.head()
df_enriched.OP_CARRIER.value_counts()
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Make a copy of the enriched dataset
df_enriched_sample = df_enriched.copy()

# Group by TRIP_NAME and count cancellations
trip_cancellation_counts = (
    df_enriched_sample.groupby('TRIP_NAME')['CANCELLED']
    .sum()
    .sort_values(ascending=False)
    .reset_index()
    .rename(columns={'CANCELLED': 'CANCELLED_COUNT'})
)

# Plot top 10 routes with most cancellations
plt.figure(figsize=(20, 6))
ax = sns.barplot(
    data=trip_cancellation_counts.head(20),
    x='TRIP_NAME',
    y='CANCELLED_COUNT',
   palette=sns.color_palette("Reds", n_colors=20)[::-1]
)

# Add bar labels
for bar in ax.containers:
    ax.bar_label(
        bar,
        padding=3,
        fontsize=12,
        fontweight='bold',
        fmt='%.0f'
    )

# Customize plot aesthetics
plt.title('Top 20 Routes with Highest no. of Cancellations', fontsize=16, fontweight='bold')
plt.xlabel('Route', fontsize=12)
plt.ylabel('Number of Cancellations', fontsize=12,fontweight='bold')
plt.xticks(rotation=0, ha='center')
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

#filtering cancelled flights as given in the instruction
df_enriched=df_enriched[df_enriched.CANCELLED==0]
#checking no. of null values
df_enriched.isna().sum()
#double checking for other values in cancelled flights
print(df_enriched.CANCELLED.value_counts())
print(df_enriched.shape)
# Converting AIR_TIME and DISTANCE to numeric 
df_enriched['AIR_TIME'] = pd.to_numeric(df_enriched['AIR_TIME'], errors='coerce')
df_enriched['DISTANCE'] = pd.to_numeric(df_enriched['DISTANCE'], errors='coerce')

# Converting FL_DATE to datetime
df_enriched['FL_DATE'] = pd.to_datetime(df_enriched['FL_DATE'], errors='coerce')

# Verifying the changes
df_enriched.dtypes
dg_graphs2=df_enriched.copy()
dg_graphs2.head()
#checking no. of null values
df_enriched.isna().sum()
- Checking Data Quality Issue in the final merged dataframe 

df_flights_1 =df_enriched.copy()
zeros   = [df_flights_1['AIR_TIME'] == 0]
negatives = df_flights_1[df_flights_1['AIR_TIME'] < 0]
print(f"Zero AIR_TIME rows: {len(zeros)}")
print(f"Negative AIR_TIME rows: {len(negatives)}")
mask = (df_flights_1['CANCELLED'] == 0) & df_flights_1['AIR_TIME'].notna()
combined = ((df_flights_1.loc[mask, 'AIR_TIME'] < 30) |
            (df_flights_1.loc[mask, 'AIR_TIME'] > 350)).sum()

print(f"Total no. of Flights less than 30 min OR over 350 min are  {combined}, which is irrelevant.")
# Distance
min_dist = df_enriched['DISTANCE'].min()
max_dist = df_enriched['DISTANCE'].max()
print(f"DISTANCE → min: {min_dist}, max: {max_dist}")

# Departure delay
min_dep = df_enriched['DEP_DELAY'].min()
max_dep = df_enriched['DEP_DELAY'].max()
print(f"DEP_DELAY → min: {min_dep}, max: {max_dep}")

# Arrival delay
min_arr = df_enriched['ARR_DELAY'].min()
max_arr = df_enriched['ARR_DELAY'].max()
print(f"ARR_DELAY → min: {min_arr}, max: {max_arr}")
df_enriched.describe()
summary = df_enriched.describe()

# downloaded csv file to manually check real values if .describe()
summary.to_csv('df_enriched_summary.csv', index=True)
#  Converting FL_DATE to datetime
df_enriched = df_enriched.copy()
df_enriched['FL_DATE'] = pd.to_datetime(df_enriched['FL_DATE'], errors='coerce')

#  Making sure numeric columns really are numeric
for col in ['DISTANCE','AIR_TIME','DEP_DELAY','ARR_DELAY','Ticket_price','OCCUPANCY_RATE']:
    df_enriched[col] = pd.to_numeric(df_enriched[col], errors='coerce')
df_enriched = df_enriched.dropna(subset=[
    'ORIGIN_AIRPORT_ID',
    'OP_CARRIER_FL_NUM',
    'DEST_AIRPORT_ID',
    'AIR_TIME',
    'CANCELLED'
])

### As per my research ,U.S. Domestic Flight Ranges

- Shortest Flight

    Distance: 24 miles (Petersburg, AK → Wrangell, AK)

    Air Time: 8–22 minutes (varies due to weather)

- Longest Flight

    Distance: 5,095 miles (Boston → Honolulu)

    Air Time: 10–11 hours
# Filter out implausible values using real U.S. flight ranges

df_enriched = df_enriched[
    (df_enriched['DISTANCE'] >= 24) & (df_enriched['DISTANCE'] <= 5095)
    # Air time: between ~8 min and ~11 hr (660 min)
    & (df_enriched['AIR_TIME'] >= 8) & (df_enriched['AIR_TIME'] <= 660)
    #  keeping delays within ±24 hrs
    & (df_enriched['DEP_DELAY'].abs() <= 1440) & (df_enriched['ARR_DELAY'].abs() <= 1440)
]

df_enriched[['DISTANCE','AIR_TIME','DEP_DELAY','ARR_DELAY']].agg(['min','max'])

# checking Null values again to make further data cleaning
df_enriched.isna().sum()
# droping out this data as less than 10 % data is null 
df_enriched = df_enriched.dropna(subset=['FL_DATE'])

df_enriched = df_enriched.dropna(subset=['ORIGIN_AIRPORT_TYPE'])

df_enriched = df_enriched.dropna(subset=['DESTINATION_AIRPORT_TYPE'])

df_enriched = df_enriched.dropna(subset=['Ticket_price'])

df_enriched.isna().sum()
print(f"FLIGHT Data Shape: {df_enriched.shape}")
df_enriched.head()
## Question 1

- The 10 busiest round trip routes in terms of number of round trip flights in the quarter.  Exclude canceled flights when performing the calculation.
valid_trips = df_enriched.copy()
trip_counts = valid_trips.groupby('TRIP_NAME').size().reset_index(name='TOTAL_FLIGHTS').sort_values(by='TOTAL_FLIGHTS', ascending=False)
# As we are considering roundtrips we will diving the total flights by 2 and convert it to integer.
# Counting total no of flights with respect to TRIP_NAME 
trip_counts['TOTAL_FLIGHTS'] = trip_counts['TOTAL_FLIGHTS']

trip_counts['TOTAL_FLIGHTS'] = round(trip_counts['TOTAL_FLIGHTS'], 2)

trip_counts = trip_counts.set_index('TRIP_NAME')

trip_counts.head()
import matplotlib.pyplot as plt
import seaborn as sns

# Extract top 10 busiest routes
top10 = trip_counts.head(10).reset_index()

# Create bar chart
fig, ax = plt.subplots(figsize=(12, 6))

# Generate reversed blue palette
palette = sns.color_palette("Blues", n_colors=10)[::-1]

# Create bar chart with color
bars = ax.bar(top10['TRIP_NAME'], top10['TOTAL_FLIGHTS'], color=palette)

# Add labels to bars
ax.bar_label(
    bars, 
    labels=[f"{v:,}" for v in top10['TOTAL_FLIGHTS']], 
    padding=4, 
    fontweight='bold'
)

# Set titles and labels
ax.set_title('Top 10 Busiest Routes by Number of Flights', fontsize=16, fontweight='bold')
ax.set_xlabel('Route (Origin → Destination)', fontsize=12)
ax.set_ylabel('Total Flights in First Quarter 2019', fontsize=12)

# Improve readability
plt.xticks(rotation=0, ha='center')
plt.tight_layout()

# Display plot
plt.show()


# Question 2

-  The 10 most profitable round trip routes (without considering the upfront airplane cost) in the quarter.  Along with the profit, show total revenue, total cost, summary values of other key components and total round trip flights in the quarter for the top 10 most profitable routes.  Exclude canceled flights from these calculations. 

df_enriched.head()
## Distance-Based Costs Calculation

Calculates the variable cost of each flight based on distance flown.

**Rates per mile:**  

- Fuel, Oil, Maintenance, Crew: \$8  

- Depreciation, Insurance, Other: \$1.18  

- **Total per-mile rate**: \$8 + \$1.18 = **\$9.18**
df_enriched['DISTANCE_COST'] = df_enriched['DISTANCE'] * (8 + 1.18)
## Airport Usage Fees Calculation

Calculates the fixed airport operational cost for each flight based on the origin and destination airport types.


- **Medium airports**: \$5,000 per landing/usage  

- **Large airports**:  \$10,000 per landing/usage  

- **Other airport types**: \$0 (fallback)

Each one-way flight incurs two charges (one at departure airport, one at arrival airport).  

A round-trip therefore sums four charges (two per leg). 

def airport_fee(airport_type):
    if airport_type == 'medium_airport':
        return 5000
    elif airport_type == 'large_airport':
        return 10000
    else:
        return 0  # fallback

df_enriched['DEP_AIRPORT_FEE'] = df_enriched['ORIGIN_AIRPORT_TYPE'].apply(airport_fee)
df_enriched['ARR_AIRPORT_FEE'] = df_enriched['DESTINATION_AIRPORT_TYPE'].apply(airport_fee)

# Total fee per one-way flight
df_enriched['AIRPORT_FEE'] = df_enriched['DEP_AIRPORT_FEE'] + df_enriched['ARR_AIRPORT_FEE']
## Delay Penalty Calculation

- For each individual departure, the first 15 minutes of delays are free, otherwise each minute costs the airline $75 in added operational costs. 

- For each individual arrival, the first 15 minutes of delays are free, otherwise each minute costs the airline $75 in added operational costs. 
**Assumptions**

-  Given a departure or arrival delay in minutes (negative, zero or positive), returns the operational cost at $75 per minute beyond the 
free 15-minute window.
 

- **On-time flights** (`DEP_DELAY = 0` or `ARR_DELAY = 0`) 

  → Cost = \$0 

- **Early flights** (`delay < 0`, e.g. –8 or –6)

  → Treated as 0 minutes of delay → Cost = \$0  

- **Short delays** (`0 < delay ≤ 15`, e.g. 11 or 14)  

  → Within free window → Cost = \$0  

- **Long delays** (`delay > 15`)  

  → Chargeable minutes = `delay – 15`  

  → Cost = `(delay – 15) × 75`  
def delay_cost(delay):
    return 0 if delay <= 15 else (delay - 15) * 75

df_enriched['DEP_DELAY_COST'] = df_enriched['DEP_DELAY'].apply(delay_cost)
df_enriched['ARR_DELAY_COST'] = df_enriched['ARR_DELAY'].apply(delay_cost)

df_enriched['TOTAL_DELAY_COST'] = df_enriched['DEP_DELAY_COST'] + df_enriched['ARR_DELAY_COST']
## Calculate Total Revenue per Flight

- Each plane can accommodate up to 200 passengers and each flight has an associated occupancy rate provided in the Flights data set. Do not use the Tickets data set to determine occupancy. 

- Baggage fee is $35 for each checked bag per flight. We expect 50% of passengers to check an average of 1 bag per flight. The fee is charged separately for each leg of a round trip flight, thus 50% of passengers will be charged a total of $70 in baggage fees for a round trip flight. 

- Disregard seasonal effects on ticket prices (i.e. ticket prices are the same in April as they are on Memorial Day or in December) 
df_enriched['PASSENGER_COUNT'] = df_enriched['OCCUPANCY_RATE'] * 200  # given plane capacity = 200
#  Estimating baggage revenue
# 50% of passengers check 1 bag charged $70 (round trip)
df_enriched['BAGGAGE_REVENUE'] = df_enriched['PASSENGER_COUNT'] * 0.5 * 35
# Ticket price= No of passenger * Price of ticket
df_enriched['TICKET_REVENUE'] = df_enriched['PASSENGER_COUNT'] * df_enriched['Ticket_price']
# Total revenue is sum of revenue generated by selling tickets and baggaage purchased
df_enriched['TOTAL_REVENUE'] = df_enriched['TICKET_REVENUE'] + df_enriched['BAGGAGE_REVENUE']
# Operational cost is something which we need to pay to Airport service fees and flight operational cost(furl,salary ,insurance etc)
df_enriched['OPERATIONAL_COST']=df_enriched['TOTAL_DELAY_COST']+df_enriched['DISTANCE_COST']+df_enriched['AIRPORT_FEE']
#Calculating proft
df_enriched['TOTAL_PROFIT'] =df_enriched['TOTAL_REVENUE']-df_enriched['OPERATIONAL_COST']
df_enriched.head()
df_enriched[['TRIP_NAME', 'OCCUPANCY_RATE', 'Ticket_price', 'DEP_DELAY','ARR_DELAY', 'TOTAL_REVENUE','OPERATIONAL_COST','TOTAL_PROFIT']].head()
df_trip_summary = df_enriched[
    ['TRIP_NAME','OCCUPANCY_RATE','Ticket_price',
     'DEP_DELAY','ARR_DELAY','TOTAL_REVENUE',
     'OPERATIONAL_COST','TOTAL_PROFIT']
]
- For things that don’t add up (like how full the plane is, how late it is, or how much one ticket costs), we take the average so we know the “typical” flight.

- For things that do add up (like total money made or spent), we take the sum so we know exactly how much that route earned or cost over the whole quarter.
df_trip_summary = df_trip_summary.groupby('TRIP_NAME').agg({
    'OCCUPANCY_RATE': 'mean',      # avg occupancy rate per trip
    'Ticket_price': 'mean',     # avg ticket fare per trip
    'DEP_DELAY': 'mean',           # avg departure delay per trip
    'ARR_DELAY': 'mean',           # avg arrival delay per trip
    'TOTAL_REVENUE': 'sum',       # sum revenue per flight-leg within that trip
    'OPERATIONAL_COST': 'sum',          # sum operational cost per flight-leg
    'TOTAL_PROFIT': 'sum'         # sum profit per flight-leg
}).reset_index()
df_trip_summary11 = (
    df_enriched.groupby('TRIP_NAME')
    .agg(
        LEG_COUNT=('TRIP_NAME', 'size'),            # total number of one-way flights (legs)
        OCCUPANCY_RATE=('OCCUPANCY_RATE', 'mean'),  # avg occupancy rate per route
        TICKET_PRICE=('Ticket_price', 'mean'),      # avg ticket fare per route
        DEP_DELAY=('DEP_DELAY', 'mean'),            # avg departure delay
        ARR_DELAY=('ARR_DELAY', 'mean'),            # avg arrival delay
        TOTAL_REVENUE=('TOTAL_REVENUE', 'sum'),     # total revenue
        OPERATIONAL_COST=('OPERATIONAL_COST', 'sum'),  # total operating cost
        TOTAL_PROFIT=('TOTAL_PROFIT', 'sum')        # total profit
    )
    .reset_index()
)

df_trip_summary11.to_csv('df_tableau.csv', index=False)  

df_enriched.to_csv('df_enriched1.csv', index=False)  

def top_n_by_profit(df, n):
    return df.nlargest(n, 'TOTAL_PROFIT')


top_10_profitable_routes = top_n_by_profit(df_trip_summary, 10)
### Top 10 Profitalble Routes of 2019 Q1
top_10_profitable_routes.head(10)
top_10_profitable_routes.to_csv('df_top10profitable_tableau.csv', index=False)  
import numpy as np
import matplotlib.pyplot as plt


def plot_improved_financial_clusters(
    df,
    route_col: str,
    revenue_col: str,
    profit_col: str,
    top_n: int = 10,
    figsize: tuple = (10, 6),
):
    """
    Ploting a horizontal grouped bar chart of revenue vs. profit (in $M), with
    profit margin annotations, average‐profit reference line
    """
    #selecting & sorting top‐N by profit
    top = (
        df
        .sort_values(by=profit_col, ascending=False)
        .head(top_n)
        .reset_index(drop=True)
    )

    # converting to millions
    rev_m  = top[revenue_col] / 1e6
    prof_m = top[profit_col]  / 1e6
    margin = prof_m / rev_m * 100

    # y positions
    y = np.arange(len(top))
    h = 0.4  # bar height

    #colour 
    cmap = plt.get_cmap('tab10')
    base_color, prof_color = cmap(0), cmap(1)
    highlight_color = '#20ab1f'  # for top route

    # plot
    fig, ax = plt.subplots(figsize=figsize)
    for i in y:
        # revenue bar
        ax.barh(i + h/2,
                rev_m.iloc[i],
                height=h,
                color=highlight_color if i == 0 else base_color,
                alpha=0.8,
                label='_nolegend_')
        # profit bar
        ax.barh(i - h/2,
                prof_m.iloc[i],
                height=h,
                color=prof_color,
                alpha=0.8,
                label='_nolegend_')
        # margin annotation
        ax.text(
            prof_m.iloc[i] + 0.5,
            i - h/2,
            f"{margin.iloc[i]:.1f}%",
            va='center',
            fontweight='bold'
        )

    #average profit reference line
    avg_prof = prof_m.mean()
    ax.axvline(avg_prof, linestyle='--', linewidth=1,
               color='gray', label=f"Avg Profit: {avg_prof:.1f} M")

    # axes & styling
    ax.set_yticks(y)
    ax.set_yticklabels(top[route_col])
    ax.invert_yaxis()  # highest profit on top
    ax.set_xlabel("Millions USD ($M)", fontsize=12)
    ax.set_title("Top 10 Profitable Routes: Revenue vs Profit", fontsize=16, fontweight='bold')
    ax.grid(axis='x', alpha=0.3)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    # legend
    handles = [
        plt.Line2D([], [], color=base_color, lw=6, label="Revenue"),
        plt.Line2D([], [], color=prof_color, lw=6, label="Profit"),
        plt.Line2D([], [], linestyle='--', color='gray', label="Avg Profit")
    ]
    ax.legend(handles=handles, loc='lower right')

    plt.tight_layout()
    plt.show()

plot_improved_financial_clusters(
    df=top_10_profitable_routes,
    route_col='TRIP_NAME',
    revenue_col='TOTAL_REVENUE',
    profit_col='TOTAL_PROFIT',
    top_n=10
)

# Question 3

- The 5 round trip routes that you recommend to invest in based on any factors that you choose.

- Score on-time performance: We turn each route’s average departure & arrival delays into a 0–1 punctuality_score (1 = perfectly on time; 0 = very late).

- Score payback speed: We calculate months to recover the $90 M investment (using Q1 profit), normalize against the slowest route, and flip it into a 0–1 payback_score (1 = fastest recovery; 0 = slowest).

- combined_score = 0.5* punctuality_score + 0.5* payback_score and pick the top 5 routes by that score.

- Why equal weights? Because the airline’s motto “On time” is as critical as recouping its investment quickly—so giving both factors a weight of 0.5 treats them as equally important.
import pandas as pd

def compute_punctuality_score(df: pd.DataFrame, delay_threshold: float = 15.0) -> pd.DataFrame:
    """
    Higher score if average departure+arrival delays are low.
    Delay penalty = (dep_delay_clipped + arr_delay_clipped) / threshold
    punctuality_score = max(0, 1 - penalty)
    """
    df = df.copy()
    # only counting positive (late) delays
    df['dep_late'] = df['DEP_DELAY'].clip(lower=0)
    df['arr_late'] = df['ARR_DELAY'].clip(lower=0)
    df['delay_penalty'] = (df['dep_late'] + df['arr_late']) / delay_threshold
    df['punctuality_score'] = (1 - df['delay_penalty']).clip(lower=0)
    return df.drop(columns=['dep_late','arr_late','delay_penalty'])


def compute_payback_period(df: pd.DataFrame,
                           investment_per_route: float = 90_000_000,
                           profit_period_months: float = 3.0) -> pd.DataFrame:
    """
    Given TOTAL_PROFIT over a known period (Quarter 1 so 3 months):
      monthly_profit = TOTAL_PROFIT / profit_period_months
      payback_months = investment / monthly_profit
    """
    df = df.copy()
    df['monthly_profit'] = df['TOTAL_PROFIT'] / profit_period_months
    df['payback_months'] = investment_per_route / df['monthly_profit']
    return df.drop(columns=['monthly_profit'])


def score_payback(df: pd.DataFrame) -> pd.DataFrame:
    """
    Turning payback_months into a 0–1 score (faster payback is closer to 1).
    Using max observed payback to normalize it.
    """
    df = df.copy()
    max_pb = df['payback_months'].replace([pd.NA, float('inf')], 0).max()
    df['payback_score'] = (1 - (df['payback_months'] / max_pb)).clip(lower=0)
    return df


def recommend_routes(df: pd.DataFrame,
                     n: int = 5,
                     invest_per_route: float = 90_000_000,
                     profit_period_months: float = 3.0,
                     weight_punctuality: float = 0.5,
                     weight_payback: float = 0.5) -> pd.DataFrame:
    """
    This will Returns the top‐n routes ranked by combined_score:
      combined_score = w1 * punctuality_score + w2 * payback_score
    """
    df1 = compute_punctuality_score(df)
    df2 = compute_payback_period(df1, invest_per_route, profit_period_months)
    df3 = score_payback(df2)
    df3['combined_score'] = (
        weight_punctuality * df3['punctuality_score'] +
        weight_payback     * df3['payback_score']
    )
    return df3.sort_values('combined_score', ascending=False).head(n)


top5 = recommend_routes(top_10_profitable_routes , n=5,
                        invest_per_route=90e6,
                        profit_period_months=3,
                        weight_punctuality=0.5,
                        weight_payback=0.5)
print(top5[['TRIP_NAME','punctuality_score','payback_score','payback_months','combined_score']])

top5.head()
### TOP 5 Recommended Routes after analysis
top_n = top5.nlargest(5, 'combined_score')
print(top_n[['TRIP_NAME','punctuality_score','payback_months','combined_score']])
# Question 4

- The number of round trip flights it will take to breakeven on the upfront airplane cost for each of the 5 round trip routes that you recommend. Print key summary components for these routes. 
# Counting Number of flights per Trip Name so using enriched data

df_count = df_enriched[['TRIP_NAME','TOTAL_PROFIT']]
# 1-way leg counts per route

leg_counts = df_count['TRIP_NAME'].value_counts()  

top5_route= top_n.copy()

#merging in the Q1 leg counts
top5_route['leg_count'] = top5_route['TRIP_NAME'].map(leg_counts)

#calculating how many Q1 round-trips that is
top5_route['Round_Trips_Q1'] = top5_route['leg_count'] / 2

#average profit per round-trip in Q1
top5_route['Profit_per_Round_Trip'] = top5_route['TOTAL_PROFIT'] / top5_route['Round_Trips_Q1']

#break-even round-trips to recoup $90 M
top5_route['Break_Even_Roundtrips'] = (90_000_000/ top5_route['Profit_per_Round_Trip']).round().astype(int)

print(top5_route[[
    'TRIP_NAME',
    'TOTAL_PROFIT',
    'Round_Trips_Q1',
    'Profit_per_Round_Trip',
    'Break_Even_Roundtrips'
]])

### Top 5 Recommendations and their Summary:

JFK–LAX
CLT–FLO 
CLT_MYR  
CLT_ILM  
ATL_CLT
top5_route.head()
print(top5_route[['TRIP_NAME','Profit_per_Round_Trip','Break_Even_Roundtrips']])
top5_route.to_csv('df_top5.csv', index=False)  
import matplotlib.pyplot as plt
import numpy as np

# Define a cohesive color scheme as per graph
colors = {
    'punctuality': '#4C72B0',   # blue
    'break_even':  '#8172B2',   # purple
    'revenue':     '#4C72B0',   # blue
    'cost':        '#DD8452',   # orange
    'profit':      '#55A868',   # green
    'scatter_all': '#A0CBE8',   # light blue
    'scatter_top': '#E24A33'    # red
}

def plot_top5_punctuality(top5_route):
    """Vertical bar chart of the top 5 routes by punctuality_score."""
    df = top5_route.nlargest(5, 'punctuality_score').reset_index(drop=True)
    plt.figure(figsize=(10,6))
    bars = plt.bar(df['TRIP_NAME'], df['punctuality_score'], 
                   color=colors['punctuality'], edgecolor='black')
    plt.title('Top 5 Routes by Punctuality Score', fontsize=18, fontweight='bold')
    plt.ylabel('Punctuality Score (0–1)', fontsize=14)
    plt.xticks(rotation=0, ha='center', fontsize=12)
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    for bar in bars:
        h = bar.get_height()
        plt.annotate(f'{h:.2f}', xy=(bar.get_x()+bar.get_width()/2, h),
                     xytext=(0,5), textcoords='offset points',
                     ha='center', va='bottom', fontsize=12)
    plt.tight_layout()
    plt.show()

def plot_break_even(top5_route):
    """Horizontal bar chart of break-even round-trips for top 5 routes."""
    df = top5_route.sort_values('Break_Even_Roundtrips', ascending=False).reset_index(drop=True)
    plt.figure(figsize=(10,6))
    bars = plt.barh(df['TRIP_NAME'], df['Break_Even_Roundtrips'], 
                    color=colors['break_even'], edgecolor='black')
    plt.title('Break-Even Round-Trips for Top 5 Routes', fontsize=18, fontweight='bold')
    plt.xlabel('Round-Trips to Recoup $90M', fontsize=14)
    plt.yticks(fontsize=12)
    plt.grid(axis='x', linestyle='--', alpha=0.5)
    for bar in bars:
        w = bar.get_width()
        plt.annotate(f'{int(w)}', xy=(w, bar.get_y()+bar.get_height()/2),
                     xytext=(5,0), textcoords='offset points',
                     ha='left', va='center', fontsize=12)
    plt.tight_layout()
    plt.show()

def plot_profit_anatomy(top5_route):
    """Clustered bar chart of Total Revenue, Operational Cost, and Total Profit for top 5."""
    df = top5_route.sort_values('TOTAL_PROFIT', ascending=False).reset_index(drop=True)
    x = np.arange(len(df))
    w = 0.25
    fig, ax = plt.subplots(figsize=(12,6))
    bars1 = ax.bar(x - w, df['TOTAL_REVENUE'],     w, label='Total Revenue',     color=colors['revenue'], edgecolor='black')
    bars2 = ax.bar(x,       df['OPERATIONAL_COST'],w, label='Operational Cost',    color=colors['cost'],    edgecolor='black')
    bars3 = ax.bar(x + w,   df['TOTAL_PROFIT'],    w, label='Total Profit',       color=colors['profit'],  edgecolor='black')
    ax.set_title('Revenue vs Cost vs Profit for Top 5 Routes', fontsize=18, fontweight='bold')
    ax.set_ylabel('USD in Millions ($)', fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(df['TRIP_NAME'], rotation=0, ha='center', fontsize=12)
    ax.grid(axis='y', linestyle='--', alpha=0.5)
    for bars in (bars1, bars2, bars3):
        for bar in bars:
            h = bar.get_height()
            ax.annotate(f'{h:,.0f}', xy=(bar.get_x()+bar.get_width()/2, h),
                        xytext=(0,5), textcoords='offset points',
                        ha='center', va='bottom', fontsize=11)
    ax.legend(fontsize=12)
    plt.tight_layout()
    plt.show()

def plot_punctuality_vs_payback(top5_route):
    """Scatter of all routes (punctuality vs payback), highlighting the top 5."""
    plt.figure(figsize=(10,6))

    # highlight top 5
    top = top5_route
    plt.scatter(top['punctuality_score'], top['payback_months'],
                s=100, color=colors['scatter_top'], edgecolor='black', label='Top 5')
    for _, r in top.iterrows():
        plt.text(r['punctuality_score'], r['payback_months'], r['TRIP_NAME'],
                 fontsize=10, ha='right', va='bottom')
    plt.title('Punctuality vs Payback Period', fontsize=18, fontweight='bold')
    plt.xlabel('Punctuality Score (0–1)', fontsize=14)
    plt.ylabel('Payback Period (Months)', fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.legend(fontsize=12)
    plt.tight_layout()
    plt.show()

plot_top5_punctuality(top5_route)
plot_break_even(top5_route)
plot_profit_anatomy(top5_route)
plot_punctuality_vs_payback( top5_route)

### Graphs of Data quality issues
dq_graph.head()
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

def plot_outliers_all_data(df_flights, df_tickets, fare_col='ITIN_FARE'):
    """
    Boxplots to check Data quality to identify outliers:
      - DISTANCE, AIR_TIME, DEP_DELAY, ARR_DELAY from orignal data
      
    Coerces columns to numeric, reports and plots outliers.
    """
    metrics = [
        (df_flights,      'DISTANCE',    'Distance (miles)'),
        (df_flights,      'AIR_TIME',    'Air Time (minutes)'),
        (df_flights,      'DEP_DELAY',   'Departure Delay (minutes)'),
        (df_flights,      'ARR_DELAY',   'Arrival Delay (minutes)')
    ]
    
    # Validating fare column
    if fare_col in df_tickets.columns:
        metrics.append((df_tickets, fare_col, f'{fare_col} (USD)'))
    else:
        raise KeyError(f"Ticket prices DataFrame does not contain column '{fare_col}'. "
                       f"Available columns: {list(df_tickets.columns)}")
    
    for df, col, label in metrics:
        # Coerce to numeric
        series = pd.to_numeric(df[col], errors='coerce').dropna()
        
        # Calculate IQR
        Q1, Q3 = np.percentile(series, [25, 75])
        IQR = Q3 - Q1
        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        
        # Identify outliers
        outliers = series[(series < lower) | (series > upper)]
        print(f"{label}: {len(outliers)} outliers (<{lower:.2f} or >{upper:.2f})")
        
        # Plot
        plt.figure(figsize=(8, 4))
        plt.boxplot(
            series,
            vert=False,
            patch_artist=True,
            boxprops=dict(facecolor='#AED6F1', edgecolor='#2471A3'),
            medianprops=dict(color='#C0392B', linewidth=2),
            whiskerprops=dict(color='#2471A3'),
            capprops=dict(color='#2471A3'),
            flierprops=dict(marker='o', markerfacecolor='red', markersize=5, alpha=0.6)
        )
        plt.title(f"{label} Distribution and Outliers Highlighted", fontsize=14, fontweight='bold')
        plt.xlabel(label, fontsize=12)
        plt.tight_layout()
        plt.show()


plot_outliers_all_data(df_flights, df_tickets, fare_col='ITIN_FARE')
